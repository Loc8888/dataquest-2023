{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: fastwarc in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.14.2)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from fastwarc) (4.64.1)\n",
      "Requirement already satisfied: brotli in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from fastwarc) (1.0.9)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from fastwarc) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet warcio ftfy langid blingfire bs4 fastwarc fastcore fasttext\n",
    "! pip install --upgrade scikit-learn\n",
    "! pip install fastwarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from fastcore.parallel import parallel\n",
    "import blingfire\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "import itertools\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "- Construct a vocubulary of 6-12 character n-grams from the seed websites\n",
    "- Using the above vocubulary, create a TFIDF matrix of all of the data\n",
    "- Create a single document using the average of the seed data\n",
    "- Find the closest neighbors from these single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read WARC files\n",
    "\n",
    "from fastwarc import ArchiveIterator\n",
    "from fastwarc.stream_io import PythonIOStreamAdapter\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "def retrieve_record(offset, stream):\n",
    "    stream.seek(offset)\n",
    "    payload = BytesIO()\n",
    "    try:\n",
    "        record = next(ArchiveIterator(stream))\n",
    "        headers = record.headers\n",
    "        buf = record.reader.read(4096)\n",
    "        while buf:\n",
    "            payload.write(buf)\n",
    "            buf = record.reader.read(4096)\n",
    "    except Exception as e:\n",
    "        print(e) # sensible handling here\n",
    "        return None\n",
    "    return headers, payload\n",
    "\n",
    "def extract(offset,f):\n",
    "    try:\n",
    "        headers, payload = retrieve_record(offset, f)\n",
    "        payload.seek(0)\n",
    "        payload = payload.read()\n",
    "        extracted = dict(headers)\n",
    "        extracted['offset'] = str(offset)\n",
    "        extracted['payload'] = payload\n",
    "    except:\n",
    "        extracted = {\"error\":True}\n",
    "\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitToScorer(dataframe,accessKey:str, scoringURL:str, teamName:str='NoTeamGiven', verbose=False):\n",
    "    \"\"\" Returns the score of your submission. See example notebook for submission requirements. \"\"\"\n",
    "\n",
    "    import requests, pandas\n",
    "\n",
    "    score = None\n",
    "    x = requests.post(scoringURL,\n",
    "        params={\"code\":accessKey},\n",
    "        headers={'teamName':teamName},\n",
    "        json=dataframe.to_dict())\n",
    "\n",
    "    if 200 == x.status_code:\n",
    "        score = float(x.text.split(':')[1].strip('}'))\n",
    "        if verbose:\n",
    "            print('Submission returning 200. Our score:')\n",
    "            print(x.text)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Non-200 status code returned:')\n",
    "            print(x.status_code)\n",
    "            print(x.text)\n",
    "        pass\n",
    "    \n",
    "    return [score, x.status_code, x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(fnames):\n",
    "    f1 = open(submission_template_fpath,'r')\n",
    "    js = json.load(f1)\n",
    "    f1.close()\n",
    "\n",
    "    df = pd.DataFrame.from_dict(js)\n",
    "    \n",
    "    d = list()\n",
    "    for fname in fnames:\n",
    "        theme_num = fname.split('-')[-1][0]\n",
    "        d = d + [(ln.strip() + '\\t' + theme_num).split('\\t') for ln in open(fname,'r').readlines()]\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    df.columns = ['score', 'urls', 'sample_content', 'theme']\n",
    "    del df['score']\n",
    "    del df['sample_content']\n",
    "    df[[\"theme\"]] = df[[\"theme\"]].apply(pd.to_numeric)\n",
    "\n",
    "    #scoringURL=\"https://dq23score.azurewebsites.net/api/DQ23ValidationScoreUpload\"\n",
    "    #accessKey=\"hUSP8Q5nhnJmurXATzsVRQhrjMMXYzRy9oaVPbkv5jaHAzFuLlNgrA==\"\n",
    "    accessKey = \"xCYVOL7dV4ow4XeMbqC6rIyAtsdkbp_twfdIaG8aLDXaAzFuKq4PaA==\"\n",
    "    scoringURL = 'https://dq23grandfinal.azurewebsites.net/api/DQ23Train'\n",
    "    \n",
    "    score, statuscode, responseText = SubmitToScorer(df,accessKey,scoringURL,teamName='SAY NO TO TECHNICAL DEBT',verbose=True)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "class LanguageIdentification:\n",
    "\n",
    "    def __init__(self):\n",
    "        pretrained_lang_model = \"/home/azureuser/cloudfiles/code/Examples/models/lid.176.bin\"\n",
    "        self.model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "    def predict_lang(self, text):\n",
    "        predictions = self.model.predict(text, k=1) # returns top 2 matching languages\n",
    "        return predictions[0][0].split(\"__\")[-1]\n",
    "\n",
    "LANGUAGE = LanguageIdentification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(content, do_langid = True, do_ftfy = False):\n",
    "    try:\n",
    "        content = content.decode(\"UTF-8\")\n",
    "    except:\n",
    "        content = str(content)\n",
    "        \n",
    "    parsed = BeautifulSoup(content).get_text().lower()\n",
    "    if do_ftfy:\n",
    "        ret = {\"content\": ftfy.fix_text(' '.join(parsed.text.split()))}\n",
    "    else:\n",
    "        ret = {\"content\": ' '.join(parsed.split())}\n",
    "    if do_langid:\n",
    "        try:\n",
    "            ret['lang'] = LANGUAGE.predict_lang(ret['content'])\n",
    "        except:\n",
    "            ret['lang'] = None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_offsets(fname):\n",
    "    with open(fname, \"rt\") as myfile:\n",
    "        offsets = myfile.readlines()\n",
    "    offsets = [int(i.split(\":\")[0]) for i in offsets]\n",
    "    return offsets\n",
    "\n",
    "def load_data(fname, offsets):\n",
    "    with open(fname, 'rb') as f:\n",
    "        parsed = [extract(o,f) for o in tqdm(offsets)]\n",
    "    df = pd.DataFrame(parsed)\n",
    "    # Pandas doesn't like -'s in column names\n",
    "    df.columns = df.columns.str.replace(\"-\",\"_\")\n",
    "    # Call it url\n",
    "    df['url'] = df['WARC_Target_URI']\n",
    "    return df\n",
    "\n",
    "def parse_data(df):\n",
    "    parsed = parallel(parse_html, df.payload.values, progress=False, do_langid=True)\n",
    "    df_parsed = pd.DataFrame(parsed)\n",
    "    df['payload'] = df_parsed.content\n",
    "    if 'lang' in df_parsed.columns:\n",
    "        df['lang'] = df_parsed.lang\n",
    "    return df\n",
    "\n",
    "def filter_data(df, filter_en=True):\n",
    "    if filter_en:\n",
    "        df = df[df.lang=='en']\n",
    "    df = df.drop_duplicates(subset=['url'])\n",
    "    return df\n",
    "\n",
    "def create_tfidf(df, min_df=5, max_df=0.05, ngram_range=(1,1), analyzer='word', vocabulary=None):\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, analyzer=analyzer, vocabulary=vocabulary, \\\n",
    "                                 ngram_range=ngram_range)\n",
    "    X = vectorizer.fit_transform(df['payload'])\n",
    "    return X, vectorizer\n",
    "    \n",
    "def create_common(df, vectorizer, num_overlap=2, theme_num=None):\n",
    "    docs = df[df['label'] == True]['payload'].values\n",
    "    docs = [doc + ' ' + d['theme'][theme_num]['query'].lower() for doc in docs]\n",
    "    docs_vec = vectorizer.transform(docs)\n",
    "    r,c = docs_vec.nonzero()\n",
    "    docs_df = pd.DataFrame({'r':r, 'c':c, 'v':docs_vec[r,c].tolist()[0]})\n",
    "    docs_df = docs_df.merge(pd.DataFrame(docs_df.groupby(['c']).size().to_frame('size')), on='c')\n",
    "    docs_df = docs_df[docs_df['size'] >= num_overlap][['c', 'v']].groupby(['c']).mean().reset_index()\n",
    "\n",
    "    common_vector = csr_matrix((1, docs_vec.shape[1]), dtype=docs_vec.dtype)\n",
    "\n",
    "    for i,row in docs_df.iterrows():\n",
    "        common_vector[0,row['c']] = row['v']\n",
    "        \n",
    "    return common_vector\n",
    "\n",
    "def find_nearest(X, common):\n",
    "    dists = pairwise_distances(X, common, metric='cosine') \n",
    "    dists = 1 - dists # 1 is similar, 0 is far\n",
    "    dists = np.transpose(dists)[0]\n",
    "    inds = dists.argsort()[::-1]\n",
    "    return inds, dists\n",
    "\n",
    "def write_results(inds, dists, df, fname_base, theme_num):\n",
    "    seeds = d['theme'][theme_num]['seeds']\n",
    "    out = list()\n",
    "    for ind in df[df['label'] == True].index:\n",
    "        out.append(str(dists[ind]) + '\\t' + df.loc[ind]['url'] + '\\t' + df.loc[ind]['payload'][0:100])\n",
    "    for ind in inds:\n",
    "        url = df.iloc[ind]['url']\n",
    "        if url not in seeds: \n",
    "            out.append(str(dists[ind]) + '\\t' + df.iloc[ind]['url'] + '\\t' + df.iloc[ind]['payload'][0:100])\n",
    "        if len(out) >= 100:\n",
    "            break\n",
    "    out = '\\n'.join(out)\n",
    "    fname = fname_base + 'theme-' + str(theme_num) + '.tsv'\n",
    "    open(fname,'w').write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/azureuser/cloudfiles/code/Data/test'\n",
    "submission_template_fpath = '/home/azureuser/cloudfiles/code/Data/test/test.json'\n",
    "\n",
    "parsed_dir = './parsed'\n",
    "if os.path.exists(parsed_dir) == False:\n",
    "    os.mkdir(parsed_dir)\n",
    "\n",
    "results_dir = './results'\n",
    "if os.path.exists(results_dir) == False:\n",
    "    os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theme': {'3': {'fname': '/home/azureuser/cloudfiles/code/Data/test/full3.warc', 'offset': '/home/azureuser/cloudfiles/code/Data/test/full3_offsets.txt', 'query': '3.5mm headphone alternatives', 'seeds': ['https://www.whathifi.com/advice/apple-lightning-headphones-everything-you-need-to-know', 'https://www.soundguys.com/was-ditching-the-headphone-jack-a-good-idea-13825/', 'https://www.pcmag.com/picks/the-best-phones-with-a-headphone-jack', 'https://www.macworld.com/article/668694/best-lightning-headphones-for-iphone-ipad.html', 'https://www.digitaltrends.com/home-theater/sony-wh-1000xm4-alternatives-under-100-dollars/']}, '4': {'fname': '/home/azureuser/cloudfiles/code/Data/test/full4.warc', 'offset': '/home/azureuser/cloudfiles/code/Data/test/full4_offsets.txt', 'query': 'coastal garden considerations', 'seeds': ['https://www.rhs.org.uk/plants/for-places/coastal-areas', 'https://www.gardenersworld.com/how-to/grow-plants/plants-for-a-coastal-garden/', 'https://www.themiddlesizedgarden.co.uk/how-to-create-a-delightful-seaside-garden/?shared=email&msg=fail', 'https://www.daviddomoney.com/garden-by-the-coast-top-10-plants-and-flower-varieties-for-a-coastal-look/', 'https://www.thespruce.com/rock-garden-design-2130817']}, '5': {'fname': '/home/azureuser/cloudfiles/code/Data/test/full5.warc', 'offset': '/home/azureuser/cloudfiles/code/Data/test/full5_offsets.txt', 'query': 'how to write engaging content', 'seeds': ['https://venngage.com/blog/engaging-content/', 'https://www.outbrain.com/help/advertisers/engaging-content/', 'https://www.wordstream.com/blog/ws/2022/03/10/facebook-post-ideas', 'https://copyhackers.com/2016/02/how-to-write-engaging-content/', 'https://www.semrush.com/blog/content-writing-how-to-write-and-order-different-types-of-content/']}, '6': {'fname': '/home/azureuser/cloudfiles/code/Data/test/full6.warc', 'offset': '/home/azureuser/cloudfiles/code/Data/test/full6_offsets.txt', 'query': 'how to identify gemstones', 'seeds': ['http://www.wikihow.com/Identify-Gemstones', 'https://www.gemsociety.org/article/how-gems-are-identified/', 'https://www.gemsociety.org/article/how-to-identify-gems/', 'https://www.gemstones.com/articles/gemstone-how-to-identify', 'https://www.gemsociety.org/article/the-spectroscope/']}}}\n"
     ]
    }
   ],
   "source": [
    "d = json.load(open(submission_template_fpath))\n",
    "\n",
    "theme_nums = list(d['theme'].keys())\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "for theme_num in theme_nums:\n",
    "    offsets = load_offsets(d['theme'][theme_num]['offset'])\n",
    "    df = load_data(d['theme'][theme_num]['fname'], offsets)\n",
    "    df = parse_data(df)\n",
    "    df = filter_data(df, filter_en=True)\n",
    "    df = df[['url', 'payload']]\n",
    "    df['label'] = df['url'].apply(lambda x: True if x in d['theme'][theme_num]['seeds'] else False)\n",
    "\n",
    "    fname = parsed_dir + '/parsed-' + theme_num + '.tsv'\n",
    "    df.to_csv(fname, sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574     https://www.digitaltrends.com/home-theater/son...\n",
      "4519     https://www.whathifi.com/advice/apple-lightnin...\n",
      "8879     https://www.macworld.com/article/668694/best-l...\n",
      "15360    https://www.soundguys.com/was-ditching-the-hea...\n",
      "33720    https://www.pcmag.com/picks/the-best-phones-wi...\n",
      "Name: url, dtype: object\n",
      "119      https://www.thespruce.com/rock-garden-design-2...\n",
      "8146     https://www.themiddlesizedgarden.co.uk/how-to-...\n",
      "14210    https://www.gardenersworld.com/how-to/grow-pla...\n",
      "22095    https://www.daviddomoney.com/garden-by-the-coa...\n",
      "37613    https://www.rhs.org.uk/plants/for-places/coast...\n",
      "Name: url, dtype: object\n",
      "8861     https://www.wordstream.com/blog/ws/2022/03/10/...\n",
      "15627    https://copyhackers.com/2016/02/how-to-write-e...\n",
      "26060    https://www.outbrain.com/help/advertisers/enga...\n",
      "29093          https://venngage.com/blog/engaging-content/\n",
      "29489    https://www.semrush.com/blog/content-writing-h...\n",
      "Name: url, dtype: object\n",
      "13018    https://www.gemsociety.org/article/how-gems-ar...\n",
      "17345    https://www.gemsociety.org/article/how-to-iden...\n",
      "17535    https://www.gemstones.com/articles/gemstone-ho...\n",
      "19010    https://www.gemsociety.org/article/the-spectro...\n",
      "31256            http://www.wikihow.com/Identify-Gemstones\n",
      "Name: url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "for theme_num in theme_nums:\n",
    "    fname = parsed_dir + '/parsed-' + theme_num + '.tsv'\n",
    "    df = pd.read_csv(fname, sep='\\t')\n",
    "    df = df[df['url'].isna() == False]\n",
    "    df = df[df['payload'].isna() == False]\n",
    "    print(df[df['label'] == True]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3564\n",
      "\n",
      "\n",
      "\n",
      "7338\n",
      "9541\n",
      "3126\n",
      "16703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "clean_bools = [False]\n",
    "parsed_dirs = [parsed_dir]\n",
    "\n",
    "min_dfs_vocab = [3]\n",
    "min_dfs = [5]\n",
    "max_dfs = [0.2]\n",
    "num_overlaps = [1]\n",
    "ngram_ranges = [(6,12)]\n",
    "\n",
    "params1 = (itertools.product(*[clean_bools, parsed_dirs]))\n",
    "params2 = list(itertools.product(*[min_dfs_vocab, min_dfs, max_dfs, num_overlaps, ngram_ranges]))\n",
    "\n",
    "def myprocess(theme_num):\n",
    "    print(theme_num)\n",
    "    for clean_bool, parse_dir in params1:\n",
    "        fname = parse_dir + '/parsed-' + theme_num + '.tsv'\n",
    "        df = pd.read_csv(fname, sep='\\t')\n",
    "        df = df[df['url'].isna() == False]\n",
    "        df = df[df['payload'].isna() == False]\n",
    "        if clean_bool:\n",
    "            df['payload'] = df['payload'].str.replace(r'[^a-z0-9]', ' ', regex=True).str.replace('\\s+',' ', regex=True)\n",
    "        #df['label'] = df['url'].apply(lambda x: True if x in d['theme'][theme_num]['seeds'] else False)\n",
    "        for min_df_vocab, min_df, max_df, num_overlap, ngram_range in params2:\n",
    "            #print(datetime.now().time(), theme_num, min_df, max_df, num_overlap, ngram_range)\n",
    "            _, vectorizer = create_tfidf(df[df['label'] == True], min_df=min_df_vocab, max_df=1.0, ngram_range=ngram_range, analyzer='char')\n",
    "            words = vectorizer.get_feature_names_out()\n",
    "            vocabulary = dict(zip(words, range(len(words))))\n",
    "            print(len(vocabulary))\n",
    "            X, vectorizer = create_tfidf(df, min_df=min_df, max_df=max_df, ngram_range=ngram_range, analyzer='char', vocabulary=vocabulary)\n",
    "            common_vector = create_common(df, vectorizer, num_overlap=num_overlap, theme_num=theme_num)\n",
    "            inds, dists = find_nearest(X, common_vector)\n",
    "            fname_base = results_dir + '/' + '-'.join([str(x) for x in [clean_bool, min_df_vocab, min_df, max_df, num_overlap, ngram_range]]) + '-'\n",
    "            write_results(inds, dists, df, fname_base, theme_num)\n",
    "\n",
    "p = Pool(4)\n",
    "res = p.map(myprocess, theme_nums)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "fnames = glob.glob(results_dir + '/*.tsv')\n",
    "for fname in fnames:\n",
    "    theme_num = fname.split('-')[-1][0] # Encoded in the filename, probably not ideal\n",
    "    df_temp = pd.read_csv(fname, sep='\\t', header=None)\n",
    "    df_temp.columns = ['score', 'urls', 'content']\n",
    "    df_temp['theme'] = int(theme_num)\n",
    "    if df_sub.empty:\n",
    "        df_sub = df_temp\n",
    "    else:\n",
    "        df_sub = pd.concat([df_sub, df_temp], axis=0)\n",
    "\n",
    "df_sub = df_sub.reset_index(drop=True)\n",
    "del df_sub['score']\n",
    "del df_sub['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-200 status code returned:\n",
      "500\n",
      "DQ23 Error: Errored in custom code. Please speak to an admin.\n"
     ]
    }
   ],
   "source": [
    "teamName = 'SAY NO TO TECHNICAL DEBT'\n",
    "accessKey = \"xCYVOL7dV4ow4XeMbqC6rIyAtsdkbp_twfdIaG8aLDXaAzFuKq4PaA==\"\n",
    "scoringURL = 'https://dq23grandfinal.azurewebsites.net/api/DQ23Train'\n",
    "\n",
    "scoringURL=\"https://dq23grandfinal.azurewebsites.net/api/DQ23TrainScoreUpload\"\n",
    "accessKey=\"dz6Gi3PMJC6Smi3kCbelHIY4Cbh_lcxGnPsG17e_75tnAzFu7aG_ag==\"\n",
    "    \n",
    "score, statuscode, responseText = SubmitToScorer(df_sub, accessKey, scoringURL, teamName=teamName, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('SAY_NO_TO_TECHNICAL_DEBT.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission returning 200. Our score:\n",
      "{'score': 0.09264491119558448}\n"
     ]
    }
   ],
   "source": [
    "f1 = open('../test_seed_submission.json','r')\n",
    "js = json.load(f1)\n",
    "f1.close()\n",
    "\n",
    "df = pd.DataFrame.from_dict(js)\n",
    "\n",
    "scoringURL=\"https://dq23grandfinal.azurewebsites.net/api/DQ23TrainScoreUpload\"\n",
    "accessKey=\"dz6Gi3PMJC6Smi3kCbelHIY4Cbh_lcxGnPsG17e_75tnAzFu7aG_ag==\"\n",
    "#accessKey = \"xCYVOL7dV4ow4XeMbqC6rIyAtsdkbp_twfdIaG8aLDXaAzFuKq4PaA==\"\n",
    "#scoringURL = 'https://dq23grandfinal.azurewebsites.net/api/DQ23Train'\n",
    "    \n",
    "score, statuscode, responseText = SubmitToScorer(df, accessKey, scoringURL, teamName='test', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
